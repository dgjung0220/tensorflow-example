{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. build grapth using TF operation (H(x) = Wx + b)\n",
    "x_train = [1,2,3];\n",
    "y_train = [1,2,3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis data\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Minimize Gradient Descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Run/update graph and get results\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.37408 [ 1.65107167] [ 0.72059828]\n",
      "20 0.0567295 [ 0.924721] [ 0.38067007]\n",
      "40 0.0160185 [ 0.8620097] [ 0.33363685]\n",
      "60 0.0142263 [ 0.86218655] [ 0.31518224]\n",
      "80 0.0129176 [ 0.86806267] [ 0.30010554]\n",
      "100 0.011732 [ 0.87420613] [ 0.2859765]\n",
      "120 0.0106552 [ 0.88011253] [ 0.27253419]\n",
      "140 0.0096772 [ 0.88574624] [ 0.25972584]\n",
      "160 0.00878898 [ 0.89111578] [ 0.24751955]\n",
      "180 0.00798229 [ 0.89623284] [ 0.23588704]\n",
      "200 0.00724964 [ 0.90110952] [ 0.22480123]\n",
      "220 0.00658424 [ 0.90575701] [ 0.21423639]\n",
      "240 0.00597992 [ 0.91018617] [ 0.20416805]\n",
      "260 0.00543105 [ 0.91440707] [ 0.19457287]\n",
      "280 0.00493257 [ 0.91842973] [ 0.18542865]\n",
      "300 0.00447984 [ 0.92226315] [ 0.17671412]\n",
      "320 0.00406866 [ 0.92591649] [ 0.16840924]\n",
      "340 0.00369522 [ 0.92939812] [ 0.16049464]\n",
      "360 0.00335606 [ 0.93271613] [ 0.152952]\n",
      "380 0.00304803 [ 0.93587822] [ 0.14576381]\n",
      "400 0.00276827 [ 0.93889171] [ 0.13891347]\n",
      "420 0.00251419 [ 0.94176358] [ 0.13238502]\n",
      "440 0.00228342 [ 0.94450051] [ 0.12616344]\n",
      "460 0.00207384 [ 0.94710875] [ 0.12023421]\n",
      "480 0.00188349 [ 0.94959456] [ 0.11458363]\n",
      "500 0.00171062 [ 0.95196337] [ 0.10919861]\n",
      "520 0.00155361 [ 0.95422089] [ 0.1040667]\n",
      "540 0.00141102 [ 0.95637226] [ 0.09917599]\n",
      "560 0.00128151 [ 0.9584226] [ 0.09451512]\n",
      "580 0.00116389 [ 0.96037668] [ 0.09007324]\n",
      "600 0.00105706 [ 0.96223885] [ 0.08584009]\n",
      "620 0.000960036 [ 0.9640134] [ 0.08180591]\n",
      "640 0.000871925 [ 0.96570468] [ 0.07796133]\n",
      "660 0.00079189 [ 0.96731645] [ 0.07429742]\n",
      "680 0.000719211 [ 0.9688524] [ 0.07080569]\n",
      "700 0.000653201 [ 0.97031629] [ 0.06747813]\n",
      "720 0.000593242 [ 0.97171128] [ 0.06430691]\n",
      "740 0.000538795 [ 0.97304076] [ 0.06128472]\n",
      "760 0.000489343 [ 0.97430772] [ 0.05840458]\n",
      "780 0.000444426 [ 0.97551519] [ 0.05565977]\n",
      "800 0.000403638 [ 0.97666585] [ 0.05304399]\n",
      "820 0.000366591 [ 0.97776246] [ 0.05055112]\n",
      "840 0.000332944 [ 0.97880751] [ 0.04817543]\n",
      "860 0.000302386 [ 0.97980356] [ 0.04591138]\n",
      "880 0.00027463 [ 0.98075277] [ 0.04375366]\n",
      "900 0.000249423 [ 0.98165733] [ 0.04169736]\n",
      "920 0.000226531 [ 0.98251933] [ 0.03973771]\n",
      "940 0.000205737 [ 0.98334086] [ 0.03787016]\n",
      "960 0.000186855 [ 0.98412377] [ 0.03609039]\n",
      "980 0.000169704 [ 0.98486996] [ 0.03439427]\n",
      "1000 0.000154128 [ 0.98558098] [ 0.03277784]\n",
      "1020 0.00013998 [ 0.98625863] [ 0.0312374]\n",
      "1040 0.000127132 [ 0.98690444] [ 0.02976933]\n",
      "1060 0.000115464 [ 0.98751992] [ 0.02837026]\n",
      "1080 0.000104865 [ 0.98810637] [ 0.02703696]\n",
      "1100 9.52411e-05 [ 0.98866528] [ 0.02576636]\n",
      "1120 8.65002e-05 [ 0.98919803] [ 0.02455546]\n",
      "1140 7.85608e-05 [ 0.9897055] [ 0.02340149]\n",
      "1160 7.13517e-05 [ 0.99018943] [ 0.02230178]\n",
      "1180 6.48027e-05 [ 0.99065053] [ 0.02125365]\n",
      "1200 5.88532e-05 [ 0.99108988] [ 0.02025479]\n",
      "1220 5.34514e-05 [ 0.9915086] [ 0.0193029]\n",
      "1240 4.85461e-05 [ 0.99190766] [ 0.01839575]\n",
      "1260 4.40907e-05 [ 0.99228805] [ 0.01753121]\n",
      "1280 4.00437e-05 [ 0.99265045] [ 0.01670729]\n",
      "1300 3.63675e-05 [ 0.99299586] [ 0.01592211]\n",
      "1320 3.30297e-05 [ 0.993325] [ 0.01517384]\n",
      "1340 2.99985e-05 [ 0.99363869] [ 0.01446073]\n",
      "1360 2.72453e-05 [ 0.99393761] [ 0.01378114]\n",
      "1380 2.47451e-05 [ 0.99422252] [ 0.01313349]\n",
      "1400 2.24731e-05 [ 0.99449408] [ 0.01251627]\n",
      "1420 2.04106e-05 [ 0.99475282] [ 0.01192807]\n",
      "1440 1.8537e-05 [ 0.99499947] [ 0.01136745]\n",
      "1460 1.68354e-05 [ 0.99523449] [ 0.0108332]\n",
      "1480 1.52905e-05 [ 0.99545842] [ 0.01032406]\n",
      "1500 1.38867e-05 [ 0.99567187] [ 0.00983888]\n",
      "1520 1.26123e-05 [ 0.9958753] [ 0.00937647]\n",
      "1540 1.14549e-05 [ 0.99606913] [ 0.00893579]\n",
      "1560 1.04036e-05 [ 0.99625385] [ 0.00851584]\n",
      "1580 9.44874e-06 [ 0.99642986] [ 0.00811564]\n",
      "1600 8.58128e-06 [ 0.99659771] [ 0.00773425]\n",
      "1620 7.79378e-06 [ 0.99675757] [ 0.00737077]\n",
      "1640 7.07873e-06 [ 0.99690998] [ 0.00702437]\n",
      "1660 6.42835e-06 [ 0.99705517] [ 0.00669425]\n",
      "1680 5.83859e-06 [ 0.99719357] [ 0.00637965]\n",
      "1700 5.30265e-06 [ 0.99732542] [ 0.00607984]\n",
      "1720 4.81637e-06 [ 0.99745119] [ 0.00579412]\n",
      "1740 4.37442e-06 [ 0.99757087] [ 0.00552184]\n",
      "1760 3.97254e-06 [ 0.99768513] [ 0.00526234]\n",
      "1780 3.60804e-06 [ 0.99779385] [ 0.00501503]\n",
      "1800 3.27675e-06 [ 0.99789757] [ 0.00477933]\n",
      "1820 2.97612e-06 [ 0.99799633] [ 0.00455474]\n",
      "1840 2.70291e-06 [ 0.99809051] [ 0.00434069]\n",
      "1860 2.45488e-06 [ 0.99818027] [ 0.00413671]\n",
      "1880 2.22953e-06 [ 0.99826574] [ 0.0039423]\n",
      "1900 2.02509e-06 [ 0.99834722] [ 0.00375705]\n",
      "1920 1.83909e-06 [ 0.99842495] [ 0.00358049]\n",
      "1940 1.67016e-06 [ 0.99849898] [ 0.00341221]\n",
      "1960 1.51709e-06 [ 0.99856949] [ 0.00325186]\n",
      "1980 1.37786e-06 [ 0.99863666] [ 0.00309907]\n",
      "2000 1.25134e-06 [ 0.9987008] [ 0.00295345]\n"
     ]
    }
   ],
   "source": [
    "#Fit the line\n",
    "for step in range(2001) :\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
